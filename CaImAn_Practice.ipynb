{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.21","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CNMF-E demo pipeline\n##### version 2025, modified by Eunju Sung\n\nThis notebook demonstrates how to use Caiman for processing 1p microendoscopic data. It shows how to use Caiman for the following steps:\n\n1. Apply the nonrigid motion correction (NoRMCorre) algorithm for motion correction to the original movie.\n2. Apply the constrained nonnegative matrix factorization endoscopic (CNMF-E) source separation algorithm to extract an initial estimate of neuronal spatial footprint and calcium traces.\n3. Apply quality control metrics to evaluate the initial estimates to narrow them down to a final set of estimates.\n\n\\+ plot and save extracted dF/F trace and clustered heatmap\n\nreference: https://github.com/flatironinstitute/CaImAn/blob/main/demos/notebooks/demo_pipeline_cnmfE.ipynb\n\nor see CaImAn docs for more information: https://caiman.readthedocs.io/en/latest/index.html","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"# Imports and general setup","metadata":{}},{"cell_type":"code","source":"import bokeh.plotting as bpl\nimport cv2\nimport glob\nimport holoviews as hv\nfrom IPython import get_ipython\nimport logging\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport psutil\n\nimport caiman as cm\nfrom caiman.source_extraction import cnmf\nfrom caiman.source_extraction.cnmf.cnmf import load_CNMF\nfrom caiman.utils.utils import download_demo\nfrom caiman.utils.visualization import inspect_correlation_pnr, nb_inspect_correlation_pnr\nfrom caiman.motion_correction import MotionCorrect\nfrom caiman.source_extraction.cnmf import params as params\nfrom caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\nfrom caiman.utils.visualization import view_quilt\n\ntry:\n    if __IPYTHON__:\n        get_ipython().run_line_magic('load_ext', 'autoreload')\n        get_ipython().run_line_magic('autoreload', '2')\n        # get_ipython().run_line_magic('matplotlib', 'qt')  #uncomment to run in qt mode\nexcept NameError:\n    pass\n\ntry:\n    cv2.setNumThreads(0)\nexcept:\n    pass\n\nbpl.output_notebook()\nhv.notebook_extension('bokeh')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Set up logger and environment variables","metadata":{}},{"cell_type":"code","source":"# set up logging\nlogfile = None # Replace with a path if you want to log to a file\nlogger = logging.getLogger('caiman')\n# Set to logging.INFO if you want much output, potentially much more output\nlogger.setLevel(logging.WARNING)\nlogfmt = logging.Formatter('%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s')\nif logfile is not None:\n    handler = logging.FileHandler(logfile)\nelse:\n    handler = logging.StreamHandler()\nhandler.setFormatter(logfmt)\nlogger.addHandler(handler)\n\n# set env variables in case they weren't already set\nos.environ[\"MKL_NUM_THREADS\"] = \"1\"\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\nos.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Set file path and shading function","metadata":{}},{"cell_type":"code","source":"import gdown\nimport os\n\n# Extracted file ID from your link\nfile_id = \"1Cz4tGmvZBYIbK1jKYtIVoCLrwBo-02kL\"\nurl = f\"https://drive.google.com/uc?id={file_id}\"\n\n# Set desired filename\nmovie_filename = \"Ganglion.tif\"\n\n# Download file\ngdown.download(url, movie_filename, quiet=False)\n\n# Step 3: Set file path and output folder\nmovie_path = [movie_filename]\noutput_path = \"result\"\nos.makedirs(output_path, exist_ok=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"You have {psutil.cpu_count()} CPUs available in your current environment\")\nnum_processors_to_use = None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If you have already set up multiprocessing (the `cluster` variable is already in your namespace), then that cluster will be closed and a new one created.","metadata":{}},{"cell_type":"code","source":"#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\nif 'cluster' in locals():  # 'locals' contains list of current local variables\n    print('Closing previous cluster')\n    cm.stop_server(dview=cluster)\nprint(\"Setting up new cluster\")\n_, cluster, n_processes = cm.cluster.setup_cluster(backend='multiprocessing', \n                                                 n_processes=num_processors_to_use, \n                                                 ignore_preexisting=False)\nprint(f\"Successfully set up cluster with {n_processes} processes\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define parameters\nWe first set some parameters related to the data and motion correction and create a `params` object. We'll modify this parameter object later on with settings for source extraction. You can also set all the parameters at once as demonstrated in the `demo_pipeline.ipynb` notebook.\n\nNote here we are setting `pw_rigid` to `False`, as our data seems to mainly contain large-scale translational motion. We can always redo this later if it turns out to be a mistake.\n\n# Key parameters for CNMF...\n#### 1. rf (int): patch half-width\n\nrf ('receptive field') is the half width of patches that in pixels (the actual patch width is 2*rf + 1). See previous image for a representation of how the field of view is split up into patches for parallel procesing. rf should be at least 3-4 times larger than the observed neuron diameter. The larger the patch size, the less parallelization will be used by Caiman. If rf is set to None, then CNMF will be run on the entire field of view.\n\n#### 2. stride (int): patch overlap\n\nstride is the overlap between patches in pixels (the actual overlap is stride + 1). This should be at least the diameter of a neuron. The larger the overlap, the greater the computational load, but the results will be more accurate when stitching together results from different patches.\n\n#### 3. K (int): components per patch\n\nK is the expected number of components per patch. You should adapt this to the density of components in your data, and the current rf parameter. We suggest you pick K based on the more dense patches in your movie so you don't miss neurons (we want to avoid false negatives).\n\n#### 4. gSig (int, int): half-width of neurons\n\ngSig is roughly the half-width of neurons in your movie in pixels (height, width): it is the sigma parameter of a Gaussian filter run on all the images during initialization. If the filter matches the neurons, you will get a much better estimate. gSig goes with gSiz, which is the kernel size (height and width in pixels) used for the filter. See the GaussianBlur() OpenCV function for more details on the sigma and size parameters.\n\nmerge_thr (float): merge threshold\n\nIf two spatially overlapping components are correlated above merge_thr, they will be merged into one component. The correlation coefficient is calculated using their calcium traces. If Caiman identifies a \"component\" that clearly contains two overlapping components, then increase merge_thr.\n\nYou typically will set rf and stride infrequently, so K, gSig, and merge_thr are the main parameters you will tweak when analyzing a given session. Note these are not the only important parameters. They just tend to be the most important: the others tend to depend on your calcium indicator or other factors that don't vary within an experimental session.\n\n\n### all parameters\n- `fnames`: List of paths to the file(s) to be analysed. Memmap and hdf5 result files will be saved in the same directory.\n- `fr`: Imaging frame rate in frames per second.\n- `decay_time`: Length of a typical transient in seconds. decay_time is an approximation of the time scale over which to expect a significant shift in the calcium signal during a transient. It defaults to 0.4, which is appropriate for fast indicators (GCaMP6f), slow indicators might use 1 or even more. However, decay_time does not have to precisely fit the data, approximations are enough.\n- `p`: Order of the autoregressive model. p = 0 turns deconvolution off. If transients in your data rise instantaneously, set p = 1 (occurs at low sample rate or slow indicator). If transients have visible rise time, set p = 2. If the wrong order is chosen, spikes are extracted unreliably.\n- `nb`: Number of global background components. This is a measure of the complexity of your background noise. Defaults to nb = 2, assuming a relatively homogeneous background. nb = 3 might fit for more complex noise, nb = 1 is usually too low. If nb is set too low, extracted traces appear too noisy, if nb is set too high, neuronal signal starts getting absorbed into the background reduction, resulting in reduced transients.\n- `merge_thr`: Merging threshold of components after initialization. If two components are correlated more than this value (e.g. when during initialization a neuron was split in two components), they are merged and treated as one.\n- `rf`: Half-size of the patches in pixels. Should be at least 3 to 4 times larger than the expected neuron size to capture the complete neuron and its local background. Larger patches lead to less parallelization.\n- `stride`: Overlap between patches in pixels. This should be roughly the neuron diameter. Larger overlap increases computational load, but yields better results during reconstruction/denoising of the data.\n- `K`: Number of (expected) components per patch. Adapt to rf and estimated component density.\n- `gSig`: Expected half-size of neurons in pixels [rows X columns]. CRUCIAL parameter for proper component detection.\n- `gSig_filt`: The size of the kernel is given from the parameter `gSig_filt`. Motion correction performs the best when `gSig_filt` is same with `gSig`. If this is left to the default value of `None` then no spatial filtering is performed (default option, used in 2p data).\n- `method_init`: Initialization method, depends mainly on the recording method. Use greedy_roi for 2p data, corr_pnr for 1p data, and sparse_nmf for dendritic/axonal data.\n- `ssub/tsub`: Spatial and temporal subsampling during initialization. Defaults to 1 (no compression). Can be set to 2 or even higher to save resources, but might impair detection/extraction quality.\n","metadata":{}},{"cell_type":"code","source":"# dataset dependent parameters\nfrate =                        # movie frame rate\ndecay_time =                  # length of a typical transient in seconds\n\n# motion correction parameters\nmotion_correct = True    # flag for performing motion correction\npw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\ngSig_filt = (6, 6)       # sigma for high pass spatial filter applied before motion correction, used in 1p data (half-size of neurons)\nmax_shifts = (, )      # maximum allowed rigid shift\nstrides = (40, 40)       # start a new patch for pw-rigid motion correction every x pixels\noverlaps = (20, 20)      # overlap between patches (size of patch = strides + overlaps)\nmax_deviation_rigid = 5  # maximum deviation allowed for patch with respect to rigid shifts\nborder_nan = 'copy'      # replicate values along the boundaries\n\nmc_dict = {\n    'fnames': movie_path,\n    'fr': frate,\n    'decay_time': decay_time,\n    'pw_rigid': pw_rigid,\n    'max_shifts': max_shifts,\n    'gSig_filt': gSig_filt,\n    'strides': strides,\n    'overlaps': overlaps,\n    'max_deviation_rigid': max_deviation_rigid,\n    'border_nan': border_nan\n}\n\nparameters = params.CNMFParams(params_dict=mc_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Motion Correction\nThe background signal in micro-endoscopic data is very strong and makes motion correction challenging. As a first step the algorithm performs a high pass spatial filtering with a Gaussian kernel to remove the bulk of the lower-frequency background activity and enhance spatial landmarks. The size of the kernel is given from the parameter `gSig_filt`. If this is left to the default value of `None` then no preprocessing is performed (default option, used in 2p data for CNMF). \n\nAfter spatial filtering, the NoRMCorre algorithm is used to determine the motion in each frame. The inferred motion is then applied to the *original* data, not the preprocessed data, so no information is lost before source separation. The motion corrected files are saved in memory mapped format. If no motion correction is performed (i.e., `motion_correct` was set to `False`), then the file gets directly memory mapped.\n\n> For a more detailed exploration of Caiman's motion correction pipeline, see `demo_motion_correction.ipynb`. \n\nThe following also plots the discovered displacements in x- and y- directions.","metadata":{}},{"cell_type":"code","source":"%%time\n\n%matplotlib inline\nif motion_correct:\n    # do motion correction rigid\n    mot_correct = MotionCorrect(movie_path, dview=None, **parameters.get_group('motion'))\n    mot_correct.motion_correct(save_movie=True)\n    fname_mc = mot_correct.fname_tot_els if pw_rigid else mot_correct.fname_tot_rig\n    if pw_rigid:\n        bord_px = np.ceil(np.maximum(np.max(np.abs(mot_correct.x_shifts_els)),\n                                     np.max(np.abs(mot_correct.y_shifts_els)))).astype(int)\n    else:\n        bord_px = np.ceil(np.max(np.abs(mot_correct.shifts_rig))).astype(int)\n\n    bord_px = 0 if border_nan == 'copy' else bord_px\n    fname_new = cm.save_memmap(fname_mc, base_name='memmap_', order='C',\n                               border_to_0=bord_px)\nelse:  # if no motion correction just memory map the file\n    fname_new = cm.save_memmap(movie_path, base_name='memmap_',\n                               order='C', border_to_0=0, dview=dview)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%matplotlib inline\n\n# plot shifts\nplt.plot(mot_correct.shifts_rig)\nplt.legend(['x shifts', 'y shifts'])\nplt.xlabel('frames')\nplt.ylabel('pixels')\nplt.gcf().set_size_inches(6,3)\n\nplt.savefig(f\"{output_path}/motion_shifts.png\")\nplt.show()\nshift_distance = []\nfor rig in mot_correct.shifts_rig:\n    shift_distance.append(np.sqrt(np.power(rig[0],2)+np.power(rig[1],2)))\nplt.clf()\n\n# plot distance of shifts\nplt.plot(shift_distance, color = 'black', linewidth = 0.5) \nplt.legend(['shift_distance'])\nplt.xlabel('frames')\nplt.ylabel('pixels')\nplt.gcf().set_size_inches(6,3)\nplt.savefig(f\"{output_path}/motion_distance.png\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load memory mapped file\nMemory mapping is discussed in more detail in `demo_pipeline.ipynb`.","metadata":{}},{"cell_type":"code","source":"# load memory mappable file\nYr, dims, T = cm.load_memmap(fname_new)\nimages = Yr.T.reshape((T,) + dims, order='F')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tifffile import imsave\nfrom skimage import io\n\nmot_corrected = np.array(images)\nio.imsave(os.path.join(output_path, \"motion_corrected_movie.tif\"), mot_corrected)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inspect summary images and set parameters\n### Correlation-pnr plot\nFor CNMFE, Caiman uses the correlation and peak-to-noise ratio (PNR) for initialization, which will both tend to be high in regions that contain neurons. Hence, we set a threshold for both quantitites to remove the low correlation/low pnr regions and seed initialization with regions most likely to contain neuronal activity. \n\nUsing `nb_inspect_correlation_pnr()`, you can inspect the correlation and PNR images to find threshold values for these quantities: `min_corr` and `min_pnr`. You can adjust the range of values displayed in the two subplots below by choosing the Y-box select tool (third button from the left) and selecting the desired region in the histograms on the right hand side of each image. You can also use the pan button (first button on the left) to zoom/adjust the axis limits in the histogram to make it easier to see the limits.","metadata":{}},{"cell_type":"code","source":"from bokeh.io import output_notebook\noutput_notebook()\n%matplotlib inline\n\n# Subsample and inspect correlation/PNR\ncorrelation_image, peak_to_noise_ratio = cm.summary_images.correlation_pnr(\n    images[::max(T // 1000, 1)],  # subsample if T is large\n    gSig=5,                       # filter size\n    swap_dim=False                # fix orientation issue if needed\n)\n\n# Bokeh-based interactive viewer\nnb_inspect_correlation_pnr(\n    correlation_image,\n    peak_to_noise_ratio,\n    cmap='inferno'  # jet, fire, viridis are also good\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Parameter setting for CNMF-E\nEverything is now set up to run source extraction with CNMFE. We will construct a new parameter dictionary and use this to modify the *existing* `parameters` object, using the `change_params()` method.\n\nThere are *two* main differences between the CNMF and CNMFE source separation algorithms. The first is the background model (this is discussed in the sidebar below on the Ring Model). The second difference is in how the models are initialized. This is addressed below when we go over setting corr/pnr thresholds for initialization, which we did not have to do for our 2p data.\n\nFor now, note that we have set `gnb` to `0`: this is effectively the flag telling Caiman to use CNMFE instead of CNMF. ","metadata":{}},{"cell_type":"code","source":"# parameters for source extraction and deconvolution\np = 1               # order of the autoregressive system\nK = None            # upper bound on number of components per patch, in general None for CNMFE\ngSig = np.array([, ])  # expected half-width of neurons in pixels \ngSiz = 2*gSig + 1     # half-width of bounding box created around neurons during initialization\nmerge_thr = .8      # merging threshold, max correlation allowed\nrf = 20             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\nstride_cnmf = 10    # amount of overlap between the patches in pixels \ntsub = 1            # downsampling factor in time for initialization, increase if you have memory problems1\nssub = 1            # downsampling factor in space for initialization, increase if you have memory problems\ngnb = 0             # number of background components (rank) if positive, set to 0 for CNMFE\nlow_rank_background = None  # None leaves background of each patch intact (use True if gnb>0)\nnb_patch = 0        # number of background components (rank) per patch (0 for CNMFE)\nmin_corr =       # min peak value from correlation image\nmin_pnr =        # min peak to noise ration from PNR image\nssub_B = 1          # additional downsampling factor in space for background (increase to 2 if slow)\nring_size_factor = 1.5  # radius of ring is gSiz*ring_size_factor\n\nparameters.change_params(params_dict={'method_init': 'corr_pnr',  # use this for 1 photon\n                                'K': K,\n                                'gSig': gSig,\n                                'gSiz': gSiz,\n                                'merge_thr': merge_thr,\n                                'p': p,\n                                'tsub': tsub,\n                                'ssub': ssub,\n                                'rf': rf,\n                                'stride': stride_cnmf,\n                                'only_init': True,    # set it to True to run CNMF-E\n                                'nb': gnb,\n                                'nb_patch': nb_patch,\n                                'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n                                'low_rank_background': low_rank_background,\n                                'update_background_components': True,  # sometimes setting to False improve the results\n                                'min_corr': min_corr,\n                                'min_pnr': min_pnr,\n                                'normalize_init': False,               # just leave as is\n                                'center_psf': True,                    # True for 1p\n                                'ssub_B': ssub_B,\n                                'ring_size_factor': ring_size_factor,\n                                'del_duplicates': True,                # whether to remove duplicates from initialization\n                                'border_pix': bord_px});                # number of pixels to not consider in the borders)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Initialize the model using the parameters.","metadata":{}},{"cell_type":"code","source":"cnmfe_model = cnmf.CNMF(n_processes=n_processes, \n                        dview=None, \n                        params=parameters)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<div class=\"alert alert-info\">\n    <h2 >CNMF-E: The Ring Model</h2>\n   Background activity is very ill-behaved with 1p recordings: it often fluctuates locally and is much larger in magnitude than the neural signals we want to extract. In other words, the large-scale background model used for CNMF is not sufficient for most 1p data. Hence, Pengcheng Zhou and others came up with a localized model of background activity for CNMFE: the background at each pixel is represented as the weighted sum of activity from a circle (or ring) of pixels a certain distance from that pixel. The distance of this ring from the reference pixel is set by the <em>ring_size_factor</em> parameter. This more complex pixel-by-pixel background model explains why CNMFE is computationally more expensive than CNMF, and also why it works better to mop up large-scale localized background noise in  1p data. \n    \n<p>When you set <em>gnb</em> in the CNMF model (usually to 1 or 2), you are setting the number of global background components. The fact that you can get away with so few is testament to how well-behaved the background activity is in 2p recordings. When we set <em>gnb</em> to 0 in Caiman, this is a flag telling Caiman's back end to switch to the more complicated ring model of the background activity.</p>\n\nFor more details on CNMFE you can see the <a href=\"https://elifesciences.org/articles/28728\">original paper</a> and the <a href=\"https://elifesciences.org/articles/38173\">Caiman paper</a>. \n</div>","metadata":{}},{"cell_type":"markdown","source":"## Key parameters for CNMFE\nThe key parameters for CNMFE are slightly different than for CNMF, but with some overlap. As we'll see, because of the high levels of background activity, we can't initialize the same way as with CNMF. We have two new important parameters directly related to initialization that come into play: `min_corr` and `min_pnr`. ","metadata":{}},{"cell_type":"markdown","source":"`rf` (int): *patch half-width*\n> `rf`, which stands for 'receptive field', is the half width of patches in pixels. The patch width is `2*rf + 1`. `rf` should be *at least* 3-4 times larger than the observed neuron diameter. The larger the patch size, the less parallelization will be used by Caiman. If `rf` is set to `None`, then CNMFE will be run on the entire field of view.\n\n`stride` (int): *patch overlap*\n> `stride` is the overlap between patches in pixels (the actual overlap is `stride_cnmf + 1`). This should be at least the diameter of a neuron. The larger the overlap, the greater the computational load, but the results will be more accurate when stitching together results from different patches. This param should probably have been called 'overlap' instead of 'stride'.\n\n`gSig (int, int)`: *half-width of neurons*\n> `gSig` is roughly the half-width of neurons in your movie in pixels (height, width). It is the standard deviation of the mean-centered Gaussian used to filter the movie before initialization for CNMFE. It is related to the `gSiz` parameter, which is the width of the entire kernel filter.\n\n`merge_thr (float)`: *merge threshold* \n> If the correlation between two spatially overlapping components is above `merge_thr`, they will be merged into one component. \n\n`min_corr` (float): *minimum correlation*\n> Pixels from neurons tend to be correlated with their neighbors. During initialization, Caiman filters out those pixels below `min_corr` to help select seed pixels. We discuss this more below.\n\n`min_pnr` (float): *minimum peak to noise ratio*\n> Pixels from neurons tend to have a high signal-to-noise ratio. During initialization, Caiman filters out those pixels below `min_pnr` to help select seed pixels. We discuss this more below.","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-info\">\n    <h2>CNMFE initialization: More on correlation and peak-to-noise-ratio</h2>\n     <img src=\"images/mn_centered_gaussian.jpg\" align=\"right\" width=\"200\"></img>\nHow are correlation and peak-to-noise ratio actually calculated? First Caiman convolves the motion corrected movie with a <i>mean-centered Gaussian</i> (example to the right). The sigma of the Gaussian is <em>gSig</em>, and mean centering is turned on by setting <em>center_psf</em> to <em>True</em>. This mean centering creates a Gaussian with a positive peak in the middle of width <i>approximately</i> <em>gSig/2</em>, surrounded by a negative trench, and a ledge of zeros around the outer edges. This crucial preprocessing filter serves to highlight neuronal peaks and smooth away low-frequency background activity.\n\n<p>The function <em>correlation_pnr()</em> applies this mean-centered Gaussian to each frame of the motion corrected movie and returns the correlation image of that movie, as well as the peak-to-noise-ratio (PNR). The correlation image is the correlation of each pixel with its neighbors. The PNR is the ratio of the maximum magnitude at a pixel to the noise value at that pixel (it is a fast and rough measure of signal-to-noise). As mentioned above, both of these values tend to be higher in pixels that contain neurons. The CNMFE initialization procedure is to set a threshold for both quantities, take their <i>product</i>, and use the peaks in this product map to find <b>seed pixels</b> for initialization of the CNMFE source separation algorithm.</p>\n\nMore details on the initialization procedure used here can be found in the <a href=\"https://elifesciences.org/articles/28728\">CNMFE paper</a>, or by exploring the code.         \n</div>","metadata":{}},{"cell_type":"markdown","source":"## Run the CNMF-E algorithm","metadata":{}},{"cell_type":"code","source":"cnmfe_model.fit(images);","metadata":{"scrolled":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Running the algorithm creates an `estimates` class, which we discuss in detail in `demo_pipeline.ipynb`. The CNMFE `estimates` class includes almost all the same attributes as with CNMF, such as the neural spatial and temporal components `A` and `C`. \n\nIt also includes the discovered model of background activity, which is different from the CNMF model. For *CNMF* the background model is returned as low-rank matrices `b` and `f`. For CNMFE, the background model parameters are represented in the matrix `W` (the weights of the *ring model* -- discussed above -- for each pixel) as well as `b0` (a constant offset for each pixel). We will show how to reconstruct the background activity below. ","metadata":{}},{"cell_type":"markdown","source":"# Component Evaluation\nSource extraction typically produces many false positives. Our next step is quality control: separating the results into \"good\" and \"bad\" neurons using two different metrics (discussed in detail in `demo_notebook.ipynb`):\n\n- **Signal-to-noise ratio (SNR)**: a minimum SNR is set for the calcium transients (`min_SNR`).\n- **Spatial correlation**:  a minimum correlation is set between the shape of each component and the frames in the movie when that component is active (`rval_thr`). \n\n> Caiman does *not* use the CNN classifier to sort neurons based on shape for 1p data: the network was trained on 2p data. Hence, we set the `use_cnn` param to `False`. \n\nHere we set the two parameters and run `evaluate_components()` to see which pass muster:","metadata":{}},{"cell_type":"code","source":"min_SNR =             # SNR threshold\nrval_thr =  # spatial correlation threshold\n\nquality_params = {'min_SNR': min_SNR,\n                  'rval_thr': rval_thr,\n                  'use_cnn': False}\ncnmfe_model.params.change_params(params_dict=quality_params)\n\ncnmfe_model.estimates.evaluate_components(images, cnmfe_model.params, dview=cluster)\n\nprint('*****')\nprint(f\"Total number of components: {len(cnmfe_model.estimates.C)}\")\nprint(f\"Number accepted: {len(cnmfe_model.estimates.idx_components)}\")\nprint(f\"Number rejected: {len(cnmfe_model.estimates.idx_components_bad)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize results","metadata":{}},{"cell_type":"code","source":"#%% plot contour plots of accepted and rejected components\ncnmfe_model.estimates.plot_contours_nb(img=correlation_image, \n                                       idx=cnmfe_model.estimates.idx_components);","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"View traces of accepted and rejected components:","metadata":{}},{"cell_type":"code","source":"cnmfe_model.estimates.nb_view_components(img=correlation_image, \n                                        idx=cnmfe_model.estimates.idx_components,\n                                        cmap='viridis', #gray\n                                        thr=.9); #increase to see full footprint\n\nfor ith, index in enumerate(cnmfe_model.estimates.idx_components):\n    print(f\"neuron {ith+1} = ROI {index}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save and load results\n\n#### The results of Caiman are saved in an estimates object. This is stored inside the cnmf object, i.e. it can be accessed using cnmf.estimates. The variables of interest are:\n\n`estimates.A`: Set of spatial components. Saved as a sparse column format matrix with dimensions (# of pixels X # of components). Each column corresponds to a spatial component.\n\n`estimates.C`: Set of temporal components. Saved as a numpy array with dimensions (# of components X # of timesteps). Each row corresponds to a temporal component denoised and deconvolved.\n\n`estimates.b`: Set of background spatial components (for 2p analysis): Saved as a numpy array with dimensions (# of pixels X # of components). Each column corresponds to a spatial background component.\n\n`estimates.f`: Set of temporal background components (for 2p analysis). Saved as a numpy array with dimensions (# of background components X # of timesteps). Each row corresponds to a temporal background component.\n\n`estimates.S`: Deconvolved neural activity (spikes) for each component. Saved as a numpy array with dimensions (# of background components X # of timesteps). Each row corresponds to the deconvolved neural activity for the corresponding component.\n\n`estimates.YrA`: Set of residual components. Saved as a numpy array with dimensions (# of components X # of timesteps). Each row corresponds to the residual signal after denoising the corresponding component in estimates.C.\n\n`estimates.F_dff`: Set of DF/F normalized temporal components. Saved as a numpy array with dimensions (# of components X # of timesteps). Each row corresponds to the DF/F fluorescence for the corresponding component.\n\n`estimates.sn`: Standard deviation of the noise distribution. If no value is given, then sn is estimated from the data.\n\n`estimates.bl`: Fluorescence baseline value. If no value is given, then bl is estimated from the data.\n\n`estimates.b0`: The variables for one photon processing, for the baseline value for each pixel.\n\n`dF_F`: calculated delta F over F. (caution: original CaIMaN strongly recommend NOT TO use dF/F for 1p image, because the background signal is ill-behaved.","metadata":{}},{"cell_type":"markdown","source":"In fact, `dF_F`, `estimates.C`, and `detrended calcium trace` all show the same graph. Only difference is *unit* of the y axis.\n\nSee below:\n\n### Extract $\\Delta F/F$ values\nCurrently in Caiman, we don't return a true dff value for 1p data. This is because, as mentioned in `demo_pipeline.ipynb`,  Caiman normalizes to both the baseline fluorescence and background activity. The background activity in 1p is so ill-behaved (as discussed above in the sidebar on the ring model) that Caiman currently only *detrends* the data by subtracting away the baseline but not normalizing the data. This explains the warning you will see when you run the following:\n\n\n    cnmfe_model.estimates.detrend_df_f(quantileMin=8, \n                                      frames_window=250,\n                                      flag_auto=False,\n                                      use_residuals=False);  # use denoised data","metadata":{}},{"cell_type":"code","source":"from caiman.source_extraction.cnmf.utilities import extract_DF_F\nC = cnmfe_model.estimates.C\nYrA = cnmfe_model.estimates.YrA\nf = cnmfe_model.estimates.f\nA = cnmfe_model.estimates.A\nb = cnmfe_model.estimates.b\nbl = cnmfe_model.estimates.bl\nb0 = cnmfe_model.estimates.b0\nsn = cnmfe_model.estimates.sn\ndims = cnmfe_model.estimates.dims\ndF_F = extract_DF_F(Yr, A, C, bl)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"z_score = []\n\nfor roi in C:\n    std = np.std(roi)\n    mean = np.mean(roi)\n    item = [(i - mean)/std for i in roi]\n    z_score.append(item)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize accepted / rejected ROI coordinates ","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport csv\nimport os\n\nindex_list = cnmfe_model.estimates.idx_components\nindex_list_bad = cnmfe_model.estimates.idx_components_bad\nfrom matplotlib.patches import Rectangle\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\n\nfrom skimage import io\nn, y, x = images.shape\n\n########## mapping of accepted neurons ############\n\nfig, axes = plt.subplots(1,2, figsize = (32,13))\naxes[0].imshow(correlation_image, cmap='gray')\nsize = 0\nfor i in index_list:\n    rcolor = np.random.rand(3,)\n    axes[0].plot(cnmfe_model.estimates.coordinates[i]['coordinates'][1:-1,0],cnmfe_model.estimates.coordinates[i]['coordinates'][1:-1,1],\n                linewidth=3, color=rcolor)\n    height = min(cnmfe_model.estimates.coordinates[i]['coordinates'][1:-1,1])\n    axes[0].text(max(cnmfe_model.estimates.coordinates[i]['coordinates'][1:-1,0])-10, height+10, i, ha='center', va='bottom', \n                size=15,color=rcolor)\n    axes[1].plot(dF_F[i], alpha=0.6, color=rcolor)\n    size += 1\n#axes[0].legend(index_list, fontsize=10, bbox_to_anchor=(1.05, 1.0), loc='upper left')\naxes[0].set_xlim([0,x])\naxes[0].set_ylim([y,0])\naxes[0].set_title(\"MAP of accepted ROIs\", size=18, fontweight='heavy')\n# axes[0].get_legend().remove()\n# axes[1].legend(index_list, fontsize=10, bbox_to_anchor=(1.05, 1.0), loc='upper left')\naxes[1].set_title(\"Calcium traces of accepted ROIs\", size=18, fontweight='heavy')\naxes[1].set_xlabel(\"frames\",size=15)\naxes[1].set_ylabel(\"dF/F\",size=15)\n\nplt.savefig(os.path.join(output_path, \"accepted ROIs and Traces.png\"))\n\n\n\n ########## mapping of rejected neurons ############\nfig, axes = plt.subplots(1,2, figsize = (32,13))\naxes[0].imshow(correlation_image, cmap='gray')\nsize = 0\nfor i in index_list_bad:\n     rcolor = np.random.rand(3,)\n     axes[0].plot(cnmfe_model.estimates.coordinates[i]['coordinates'][1:-1,0],cnmfe_model.estimates.coordinates[i]['coordinates'][1:-1,1],\n                 linewidth=3, color=rcolor)\n     height = min(cnmfe_model.estimates.coordinates[i]['coordinates'][1:-1,1])\n     axes[0].text(max(cnmfe_model.estimates.coordinates[i]['coordinates'][1:-1,0])-10, height+10, i, ha='center', va='bottom', \n                 size=15,color=rcolor)\n     axes[1].plot(dF_F[i], alpha=0.6, color=rcolor)\n     size += 1\n#axes[0].legend(index_list, fontsize=10, bbox_to_anchor=(1.05, 1.0), loc='upper left')\naxes[0].set_xlim([0,x])\naxes[0].set_ylim([y,0])\naxes[0].set_title(\"MAP of rejected ROIs\", size=18, fontweight='heavy')\n#axes[0].get_legend().remove()\n#axes[1].legend(index_list, fontsize=10, bbox_to_anchor=(1.05, 1.0), loc='upper left')\naxes[1].set_title(\"Calcium traces of rejected_ROIs\", size=18, fontweight='heavy')\naxes[1].set_xlabel(\"frames\",size=15)\naxes[1].set_ylabel(\"dF/F\",size=15)\n\nplt.savefig(os.path.join(output_path, \"rejected ROIs and Traces.png\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save results as csv files\n\n1. `rois.csv`: accepted/rejected ROI flag (accepted = 1 means accepted, accepted=0 means rejected)\n\n2. `coordinates.csv`: coordinates and center of mass of each ROIs\n\n3. `df_f_accepted.csv`: df_f for accepted ROIs\n\n4. `df_f_rejected.csv`: df_f for rejected ROIs\n\n5. `z_score_accepted.csv`: z-score for accepted ROIs\n\n6. `z_score_rejected.csv`: z-score for rejected ROIs\n\n7. `shifts.csv`: shifted pixel according to timesteps\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n## save idx of rois and accepted flag (accepted = 1 means accepted, accepted=0 means rejected)\nfilename = os.path.join(output_path, 'rois.csv')\nnum_accepted = 0\nnum_rejected = 0\nwith open (filename, 'w', newline=\"\") as f: \n    writer = csv.writer(f)\n    writer.writerow(['RoIIdx', 'accepted'])\n    for index in range(len(cnmfe_model.estimates.C)):\n        if index in cnmfe_model.estimates.idx_components:\n            accepted = 1; num_accepted +=1\n        else:\n            accepted = 0; num_rejected += 1\n        writer.writerow([index, accepted])\n    writer.writerow(['num_accepted', num_accepted])\n    writer.writerow(['num_rejected', num_rejected])\n    f.close()\n\n## save coordinates and CoM\nfilename = os.path.join(output_path, 'coordinates.csv')\nwith open (filename, 'w', newline=\"\") as f: \n    writer = csv.writer(f)\n    writer.writerow(['RoIIdx', 'accepted', 'x', 'y', 'is_CoM'])\n    for index, item in enumerate(cnmfe_model.estimates.coordinates):\n        if index in cnmfe_model.estimates.idx_components:\n            accepted = 1\n        else:\n            accepted = 0\n        com = cnmfe_model.estimates.coordinates[index]['CoM']\n        coordinate = cnmfe_model.estimates.coordinates[index]['coordinates']\n        for ith, i in enumerate(coordinate):\n            if (ith != 0 and ith != len(coordinate)-1):\n                writer.writerow([index, accepted, i[0], i[1], '0'])\n        writer.writerow([index, accepted, com[1], com[0], '1'])\n    f.close()\n\n## save accepted df/f and rejected df/f\nall_df_f_pd =pd.DataFrame(dF_F)\naccepted_df_f = []\nrejected_df_f = []\nfor idx in cnmfe_model.estimates.idx_components:\n    accepted_df_f.append(dF_F[idx])\nfor idx in cnmfe_model.estimates.idx_components_bad:\n    rejected_df_f.append(dF_F[idx])\naccepted_df_f_pd = pd.DataFrame(accepted_df_f)\nrejected_df_f_pd = pd.DataFrame(rejected_df_f)\n\naccepted_df_f_pd = accepted_df_f_pd.transpose()\nrejected_df_f_pd = rejected_df_f_pd.transpose()\n\nn = 0\nfor idx in sorted(index_list):\n    accepted_df_f_pd.rename(columns={accepted_df_f_pd.columns[n]: f\"ROI {idx}\"}, inplace = True)\n    n += 1\naccepted_df_f_pd.insert(0,\"time(sec)\", \" \")\nfor t in range(0, len(dF_F)):\n    accepted_df_f_pd.iloc[t,0]=t/frate\n\naccepted_df_f_pd.to_csv(os.path.join(output_path,'df_f_accepted.csv'))\n\n\nn = 0\nfor idx in sorted(index_list_bad):\n    rejected_df_f_pd.rename(columns={rejected_df_f_pd.columns[n]: f\"ROI {idx}\"}, inplace = True)\n    n += 1\nrejected_df_f_pd.insert(0,\"time(sec)\", \" \")\nfor t in range(0, len(dF_F)):\n    rejected_df_f_pd.iloc[t,0]=t/frate\nrejected_df_f_pd.to_csv(os.path.join(output_path,'df_f_rejected.csv'))\n\n\n\n## save accepted zscore and rejected zscore\nall_z_score =pd.DataFrame(z_score)\naccepted_z_score = []\nrejected_z_score = []\nfor idx in cnmfe_model.estimates.idx_components:\n    accepted_z_score.append(z_score[idx])\nfor idx in cnmfe_model.estimates.idx_components_bad:\n    rejected_z_score.append(z_score[idx])\naccepted_z_score_pd = pd.DataFrame(accepted_z_score)\nrejected_z_score_pd = pd.DataFrame(rejected_z_score)\n\naccepted_z_score_pd = accepted_z_score_pd.transpose()\nrejected_z_score_pd = rejected_z_score_pd.transpose()\n\nn = 0\nfor idx in sorted(index_list):\n    accepted_z_score_pd.rename(columns={accepted_z_score_pd.columns[n]: f\"ROI {idx}\"}, inplace = True)\n    n += 1\naccepted_z_score_pd.insert(0,\"time(sec)\", \" \")\nfor t in range(0, len(dF_F)):\n    accepted_z_score_pd.iloc[t,0]=t/frate\n\naccepted_z_score_pd.to_csv(os.path.join(output_path,'z_score_accepted.csv'))\n\n\nn = 0\nfor idx in sorted(index_list_bad):\n    rejected_z_score_pd.rename(columns={rejected_z_score_pd.columns[n]: f\"ROI {idx}\"}, inplace = True)\n    n += 1\nrejected_z_score_pd.insert(0,\"time(sec)\", \" \")\nfor t in range(0, len(dF_F)):\n    rejected_z_score_pd.iloc[t,0]=t/frate\nrejected_z_score_pd.to_csv(os.path.join(output_path,'z_score_rejected.csv'))\n\n\nshift_distance_pd = pd.DataFrame(shift_distance)\nshift_distance_pd.insert(0,\"time(sec)\", \" \")\nfor t in range(0, len(dF_F)):\n    shift_distance_pd.iloc[t,0]=t/frate\nshift_distance_pd.columns = ['time(sec)', 'shifts(pixel)']\nshift_distance_pd.to_csv(os.path.join(output_path,'shift_distance.csv'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot and save extracted dF/F traces\n\nif you want to see calcium traces in ipynb environment,\n\n`see_trace` == `True`\n\nif you want to see calcium traces in local,\n\n`see_trace` = `False`","metadata":{}},{"cell_type":"code","source":"pip install seaborn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## see extracted calcium trace\nimport seaborn as sns\n%matplotlib inline\n\n# font size rescaling\ntrace_save_path = os.path.join(output_path, './traces') \nif not os.path.exists(trace_save_path):\n    os.mkdir(trace_save_path)\n\ntrace_zscore_save_path = os.path.join(output_path, './traces_zsocre') \nif not os.path.exists(trace_zscore_save_path):\n    os.mkdir(trace_zscore_save_path)\n\nsns.set_context(\"notebook\", font_scale=1)\n\n# plot df/f traces\nsee_trace = False\nt = np.arange(0, dF_F.shape[-1]/frate, 1/frate)\nfor idx, data in enumerate(dF_F):\n    if idx in cnmfe_model.estimates.idx_components:\n        plt.figure(figsize=(10,5))\n        plt.title(f'roi idx: {idx}')\n        plt.plot(t, dF_F[idx], color = 'black', linewidth = 1, alpha = 0.6)\n        plt.savefig(os.path.join(trace_save_path, f'roi{idx}.png'))\n        if see_trace:\n            plt.show()\n        else:\n            plt.close()\n\n# plot z score traces\nsee_trace = False\nt = np.arange(0, dF_F.shape[-1]/frate, 1/frate)\nfor idx, data in enumerate(dF_F):\n    if idx in cnmfe_model.estimates.idx_components:\n        plt.figure(figsize=(10,5))\n        plt.title(f'roi idx: {idx}')\n        plt.plot(t, z_score[idx], color = 'black', linewidth = 1, alpha = 0.6)\n        plt.savefig(os.path.join(trace_zscore_save_path, f'roi{idx}.png'))\n        if see_trace:\n            plt.show()\n        else:\n            plt.close()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot clustering heatmap of df_f values","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ndata_for_clustering = accepted_df_f_pd.drop(columns=[\"time(sec)\"]).T\nzscore_for_clustering = accepted_z_score_pd.drop(columns=[\"time(sec)\"]).T\n\n# font size rescaling\nsns.set_context(\"notebook\", font_scale=0.4)\nsns.set(style=\"white\")\n\n\ncg1 = sns.clustermap(\n    zscore_for_clustering,\n    method=\"ward\",        # hierarchical clustering method\n    metric=\"euclidean\",   # distance metric\n    cmap=\"inferno\",\n    figsize=(12, 10),\n    col_cluster=False, vmax=10    # 시간 축은 clustering하지 않음,\n)\n\ncg1.ax_heatmap.set_yticklabels([])\ncg1.ax_heatmap.set_ylabel(\"\")\ncg1.ax_heatmap.tick_params(left=False, bottom=False)\n\ntime_values = zscore_for_clustering.columns\ntick_step = 500\ntick_indices = [i for i, t in enumerate(time_values) if t % tick_step == 0]\n\ncg1.ax_heatmap.set_xticks(tick_indices)\ncg1.ax_heatmap.set_xticklabels([f\"{int(time_values[i]/frate)}\" for i in tick_indices], rotation=90)\ncg1.ax_heatmap.set_xlabel(\"Time (s)\")\n\n\nplt.title(\"Clustered Neural Activity (Z score)\")\nplt.tight_layout()\nplt.show()\n\n\ncg2 = sns.clustermap(\n    data_for_clustering,\n    method=\"ward\",        # hierarchical clustering method\n    metric=\"euclidean\",   # distance metric\n    cmap=\"inferno\",\n    figsize=(12, 10),\n    col_cluster=False,     # 시간 축은 clustering하지 않음,\n    vmax = 0.2\n)\ncg2.ax_heatmap.set_yticklabels([])\ncg2.ax_heatmap.set_ylabel(\"\")\ncg2.ax_heatmap.tick_params(left=False, bottom=False)\ntime_values = data_for_clustering.columns\ntick_step = 500\ntick_indices = [i for i, t in enumerate(time_values) if t % tick_step == 0]\n\ncg2.ax_heatmap.set_xticks(tick_indices)\ncg2.ax_heatmap.set_xticklabels([f\"{int(time_values[i]/frate)}\" for i in tick_indices], rotation=90)\ncg2.ax_heatmap.set_xlabel(\"Time (s)\")\n\nplt.title(\"Clustered Neural Activity (dF/F)\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Clean up open resourses\nShut down server, close logger.","metadata":{}},{"cell_type":"code","source":"cm.stop_server(dview=cluster)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Shut down logger (otherwise will not be able to delete it)\nlogging.shutdown()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"delete_logs = True\nlogging_dir = cm.paths.get_tempdir() \nif delete_logs:\n    log_files = glob.glob(logging_dir + '\\\\demo_pipeline' + '*' + '.log')\n    for log_file in log_files:\n        print(f\"Deleting {log_file}\")\n        os.remove(log_file)\nelse:\n    print(f\"If you want to inspect your logs they are in {logging_dir}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}